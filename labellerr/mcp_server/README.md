# Labellerr MCP Server (Python)

A Python-based Model Context Protocol (MCP) server for the Labellerr platform. This server provides 22 specialized tools for managing annotation projects, datasets, and monitoring operations through AI assistants like Claude Desktop and Cursor.

> **‚ö° New User?** Check out the [QUICKSTART.md](QUICKSTART.md) for a super simple 5-minute setup guide!

## üöÄ Quick Start (5 minutes)

Want to use Labellerr with your AI assistant? Follow these steps:

### Step 1: Get Your Credentials
You'll need three things from your Labellerr account:
- **API Key**
- **API Secret** 
- **Client ID**

Get these from your Labellerr dashboard at [https://pro.labellerr.com](https://pro.labellerr.com)

### Step 2: Install Dependencies
```bash
cd /path/to/SDKPython
pip install -r requirements.txt
```

### Step 3: Configure Your AI Assistant

**For Cursor:**

1. Open Cursor Settings ‚Üí Features ‚Üí Beta ‚Üí MCP Settings (or find `~/.cursor/mcp.json`)
2. Add this configuration (replace `YOUR_PATH` and credentials):

```json
{
  "mcpServers": {
    "labellerr": {
      "command": "python3",
      "args": ["/YOUR_PATH/SDKPython/labellerr/mcp_server/server.py"],
      "env": {
        "LABELLERR_API_KEY": "your_api_key_here",
        "LABELLERR_API_SECRET": "your_api_secret_here",
        "LABELLERR_CLIENT_ID": "your_client_id_here"
      }
    }
  }
}
```

**For Claude Desktop:**

1. Open `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS)
2. Add the same configuration as above

### Step 4: Restart and Test

1. **Completely quit** and reopen your AI assistant
2. Try asking: **"List all my Labellerr projects"**
3. You should see your projects! üéâ

### What You Can Do Now

Once configured, talk naturally to your AI assistant:

```
You: "Create a new image annotation project called 'Product Detection' 
     with bounding box annotations"

AI: *Creates project with dataset, annotation template, and project setup*

You: "Upload all images from /Users/me/images/products to a new dataset"

AI: *Uploads files and creates dataset*

You: "What's the progress on project abc123?"

AI: *Shows completion percentage, files annotated, reviewed, etc.*

You: "Export all accepted annotations as COCO JSON"

AI: *Creates export and provides download link*
```

---

## üöÄ Architecture

**Pure API Implementation - SDK Independent**

This MCP server is completely independent of the Labellerr SDK implementation. It makes direct REST API calls to `https://api.labellerr.com` using only the `requests` library.

### Benefits

- ‚úÖ **No SDK Dependencies** - Immune to SDK refactors and changes
- ‚úÖ **Direct API Access** - Faster, more transparent operations
- ‚úÖ **Easy to Debug** - See exact API requests and responses
- ‚úÖ **Standalone Deployment** - Can be deployed without the full SDK
- ‚úÖ **API-First** - Tracks API changes, not SDK implementation changes
- ‚úÖ **Simple Dependencies** - Only requires `requests`, `mcp`, and standard library

### Dependencies

```
requests      # HTTP client
mcp           # Model Context Protocol SDK
python-dotenv # Environment variable management
Standard library only (uuid, json, logging, asyncio)
```

## Features

- **üöÄ Project Management** - Create, list, update, and track annotation projects
- **üìä Dataset Management** - Create datasets, upload files/folders, and query information
- **üè∑Ô∏è Annotation Tools** - Upload pre-annotations, export data, and download results
- **üìà Monitoring & Insights** - Real-time progress tracking and system health monitoring
- **üîç Query Capabilities** - Search projects, get statistics, and analyze operations

## Installation

### Prerequisites

- Python 3.8 or higher
- pip
- Labellerr API credentials (API Key, API Secret, Client ID)

### Setup

1. **Navigate to the SDK directory:**
```bash
cd /Users/sarthak/Documents/MCPLabellerr/SDKPython
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Configure environment variables:**

Create a `.env` file in the SDKPython directory:

```bash
# Create .env file
touch .env
```

Edit `.env` and add your Labellerr credentials:

```env
LABELLERR_API_KEY=your_api_key_here
LABELLERR_API_SECRET=your_api_secret_here
LABELLERR_CLIENT_ID=your_client_id_here

# Optional: For integration tests
LABELLERR_TEST_DATA_PATH=/path/to/test/images
```

**Important:** Never commit your `.env` file to version control!

## Configuration

### Using with Cursor

Add to your Cursor MCP configuration file:

**Location:** `~/.cursor/mcp.json` (macOS/Linux) or `%APPDATA%\Cursor\mcp.json` (Windows)

```json
{
  "mcpServers": {
    "labellerr": {
      "command": "python3",
      "args": ["/Users/sarthak/Documents/MCPLabellerr/SDKPython/labellerr/mcp_server/server.py"],
      "env": {
        "LABELLERR_API_KEY": "your_api_key",
        "LABELLERR_API_SECRET": "your_api_secret",
        "LABELLERR_CLIENT_ID": "your_client_id"
      }
    }
  }
}
```

**Important:** 
- Replace `/Users/sarthak/Documents/MCPLabellerr/SDKPython/` with your actual path if different
- Use absolute paths
- Replace the credential placeholders with your actual credentials

After configuration:
1. Restart Cursor completely (Quit and reopen)
2. The Labellerr tools will be available in the AI assistant
3. Try asking: "List all my Labellerr projects"

### Using with Claude Desktop

Add to your Claude Desktop configuration file:

**Location:** `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS)

```json
{
  "mcpServers": {
    "labellerr": {
      "command": "python3",
      "args": ["/Users/sarthak/Documents/MCPLabellerr/SDKPython/labellerr/mcp_server/server.py"],
      "env": {
        "LABELLERR_API_KEY": "your_api_key",
        "LABELLERR_API_SECRET": "your_api_secret",
        "LABELLERR_CLIENT_ID": "your_client_id"
      }
    }
  }
}
```

## Testing

### Running Integration Tests

The integration tests verify the complete workflow using the pure API implementation:

```bash
cd /Users/sarthak/Documents/MCPLabellerr/SDKPython
python tests/integration/run_mcp_integration_tests.py
```

The test runner will:
1. Check for required environment variables
2. Prompt for any missing credentials
3. Validate credentials with the API
4. Run comprehensive integration tests
5. Show detailed test results

**Test Coverage:**
- ‚úÖ API client initialization
- ‚úÖ Dataset creation with file uploads
- ‚úÖ Annotation template creation
- ‚úÖ Project creation workflow
- ‚úÖ List and query operations
- ‚úÖ Export operations
- ‚úÖ Complete end-to-end workflow

### Direct API Client Testing

You can also test the API client directly in Python:

```python
from labellerr.mcp_server.api_client import LabellerrAPIClient

# Initialize client
client = LabellerrAPIClient(
    api_key="your_api_key",
    api_secret="your_api_secret",
    client_id="your_client_id"
)

# List projects
projects = client.list_projects()
print(f"Found {len(projects['response']['projects'])} projects")

# Get dataset
dataset = client.get_dataset("dataset_id_here")
print(dataset)

# Close client when done
client.close()
```

## Three-Step Project Creation Workflow

Projects in Labellerr follow a three-step creation process that aligns with the SDK architecture:

### Step 1: Create or Provide Dataset
- **Upload files and create dataset**, OR
- **Provide existing dataset_id**
- Dataset processing is monitored automatically (status polling)

### Step 2: Create or Provide Annotation Template  
- **Define annotation questions**, OR
- **Provide existing annotation_template_id**

### Step 3: Create Project
- **Links dataset and template together** with rotation config

### Using the `project_create` Tool

The `project_create` tool handles all three steps automatically with built-in status monitoring:

**Option A: Create Everything New (Full Workflow)**
```
You: "Create an image annotation project called 'Product Detection' 
     with files from /Users/me/images/products"

AI will automatically:
1. Upload files to GCS
2. Create dataset
3. Wait for dataset processing (polls status until ready)
4. Create annotation template from your questions
5. Create project linking everything together
```

**Option B: Use Existing Dataset**
```
You: "Create a project using existing dataset abc-123 with bounding box annotations"

AI will automatically:
1. Validate the dataset exists
2. Create annotation template
3. Create project
```

**Option C: Use Existing Template**
```
You: "Create a project with files from /path and existing template def-456"

AI will automatically:
1. Upload files and create dataset
2. Wait for dataset processing
3. Validate the template exists
4. Create project
```

**Option D: Use Both Existing Resources**
```
You: "Create a project using dataset abc-123 and template def-456"

AI will automatically:
1. Validate dataset exists
2. Validate template exists
3. Create project
```

### Using Individual Tools (Granular Control)

For step-by-step control, use separate tools:

1. **Create Dataset:**
   ```
   dataset_create or dataset_upload_folder ‚Üí get dataset_id
   ```

2. **Check Dataset Status:**
   ```
   dataset_get ‚Üí check status_code (100=processing, 300=ready, 400+=error)
   ```
   Note: `project_create` does this automatically!

3. **Create Template:**
   ```
   template_create ‚Üí get template_id
   ```

4. **Create Project:**
   ```
   project_create with dataset_id and template_id
   ```

### Dataset Status Codes

When creating datasets, they are processed asynchronously:
- **100**: Processing (still uploading/indexing files)
- **300**: Ready (dataset is ready to use)
- **400+**: Error (processing failed)

The `project_create` tool automatically waits for status 300 before proceeding.

## Available Tools (23 total)

### üìã Project Management (4 tools)
- `project_create` - Create projects with annotation guidelines
- `project_list` - List all projects
- `project_get` - Get detailed project information
- `project_update_rotation` - Update rotation configuration

### üìä Dataset Management (5 tools)
- `dataset_create` - Create new datasets
- `dataset_upload_files` - Upload individual files
- `dataset_upload_folder` - Upload entire folders
- `dataset_list` - List all datasets
- `dataset_get` - Get dataset information

### üè∑Ô∏è Annotation Operations (6 tools)
- `template_create` - Create annotation template with questions
- `annotation_upload_preannotations` - Upload pre-annotations (sync)
- `annotation_upload_preannotations_async` - Upload pre-annotations (async)
- `annotation_export` - Create annotation export
- `annotation_check_export_status` - Check export status
- `annotation_download_export` - Get export download URL

### üìà Monitoring & Analytics (4 tools)
- `monitor_job_status` - Monitor background job status
- `monitor_project_progress` - Track project progress
- `monitor_active_operations` - List active operations
- `monitor_system_health` - Check system health

### üîç Query & Search (4 tools)
- `query_project_statistics` - Get detailed project stats
- `query_dataset_info` - Get dataset information
- `query_operation_history` - View operation history
- `query_search_projects` - Search projects by name/type

## Usage Examples

### Via AI Assistant in Cursor

Once configured, you can interact naturally:

**Project Management:**
- "List all my Labellerr projects"
- "Create a new image classification project for product categorization"
- "What's the progress of project XYZ?"

**Dataset Operations:**
- "Upload images from /path/to/folder"
- "List all my datasets"
- "Create a new dataset for video annotation"

**Monitoring:**
- "Show me system health"
- "Check the progress of my active projects"
- "What operations have been performed?"

### Common Use Cases

#### 1. Create a Complete Annotation Project from Scratch

```
You: "I need to create an image annotation project for detecting cats and dogs. 
     I have 100 images in /Users/me/pets folder. Use bounding boxes."

AI will automatically execute the three-step workflow:
‚úì Step 1: Upload your 100 images ‚Üí Create dataset ‚Üí Wait for processing
‚úì Step 2: Create annotation template with bounding box tool
‚úì Step 3: Create project linking dataset and template together
‚úì Return project ID and confirmation

Note: Dataset processing is monitored automatically - you don't need to manually check status!
```

#### 2. Monitor Project Progress

```
You: "What's the status of all my projects?"

AI will show:
- List of all projects
- Completion percentage for each
- Files annotated, reviewed, accepted
- Data type and creation date
```

#### 3. Bulk Export Annotations

```
You: "Export all accepted annotations from project xyz in COCO JSON format"

AI will:
‚úì Create the export job
‚úì Monitor the export status
‚úì Provide download URL when ready
```

#### 4. Create Reusable Annotation Templates

```
You: "Create an annotation template for vehicle detection with bounding boxes"

AI will:
‚úì Create a template with the specified configuration
‚úì Return template_id for reuse in multiple projects
‚úì Template can be used with different datasets
```

#### 5. Upload Additional Data to Existing Project

```
You: "Upload the images from /Users/me/more-pets to dataset abc123"

AI will:
‚úì Scan the folder
‚úì Upload all matching files
‚úì Add them to the existing dataset
```

#### 6. Search and Query Projects

```
You: "Find all my video annotation projects"

AI will:
‚úì Search through all projects
‚úì Filter by data type "video"
‚úì Show matching projects with details
```

### Direct Python Usage

```python
import asyncio
from labellerr.mcp_server.api_client import LabellerrAPIClient

async def main():
    # Initialize client
    client = LabellerrAPIClient(
        api_key="your_api_key",
        api_secret="your_api_secret",
        client_id="your_client_id"
    )
    
    try:
        # Upload folder and create dataset
        connection_id = client.upload_folder_to_connector(
            "/path/to/images",
            "image"
        )
        
        dataset = client.create_dataset(
            dataset_name="My Dataset",
            data_type="image",
            connection_id=connection_id
        )
        
        print(f"Dataset created: {dataset['response']['dataset_id']}")
        
        # Create annotation template
        template = client.create_annotation_template(
            template_name="My Template",
            data_type="image",
            questions=[{
                "question_number": 1,
                "question": "Object",
                "question_id": "uuid-here",
                "option_type": "BoundingBox",
                "required": True,
                "options": [{"option_name": "#FF0000"}],
                "color": "#FF0000"
            }]
        )
        
        print(f"Template created: {template['response']['template_id']}")
        
    finally:
        client.close()

asyncio.run(main())
```

## Architecture Details

```
SDKPython/
‚îú‚îÄ‚îÄ labellerr/
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py          # Main MCP server (Pure API)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_client.py      # Pure API client (no SDK deps)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py           # Tool definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md          # This file
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_mcp_server.py              # Integration tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_mcp_integration_tests.py    # Interactive test runner
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ .env                       # Environment variables (not in git)
‚îî‚îÄ‚îÄ requirements.txt           # Dependencies
```

### API Client Implementation

The `api_client.py` module provides a pure API implementation:

- **Direct HTTP Calls**: Uses `requests` library directly
- **Session Management**: Connection pooling and retry strategy
- **Dataset Status Polling**: Automatically monitors dataset processing
- **Error Handling**: Comprehensive error handling and logging
- **File Uploads**: Handles GCS signed URL uploads
- **Type Hints**: Full type annotations for better IDE support

**Key Classes:**
- `LabellerrAPIClient` - Main API client
- `LabellerrAPIError` - Custom exception for API errors

**API Endpoints Implemented:**
- `/datasets/*` - Dataset operations
- `/projects/*` - Project operations
- `/annotations/*` - Template operations
- `/exports/*` - Export operations
- `/connectors/*` - File upload operations

## How It Works

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             You in Cursor/Claude Desktop                    ‚îÇ
‚îÇ  "Create an image annotation project"                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ Natural Language
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   AI Assistant                              ‚îÇ
‚îÇ  ‚Ä¢ Understands your intent                                  ‚îÇ
‚îÇ  ‚Ä¢ Identifies tool: "project_create"                       ‚îÇ
‚îÇ  ‚Ä¢ Extracts parameters                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ MCP Protocol (JSON-RPC)
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              server.py (MCP Server)                        ‚îÇ
‚îÇ  ‚Ä¢ Receives tool call request                              ‚îÇ
‚îÇ  ‚Ä¢ Orchestrates three-step workflow:                       ‚îÇ
‚îÇ    1. Upload files ‚Üí Create dataset ‚Üí Poll status          ‚îÇ
‚îÇ    2. Create annotation template                           ‚îÇ
‚îÇ    3. Create project (links dataset + template)            ‚îÇ
‚îÇ  ‚Ä¢ Automatically monitors dataset processing               ‚îÇ
‚îÇ  ‚Ä¢ Tracks operation history                                ‚îÇ
‚îÇ  ‚Ä¢ Caches results                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ Uses
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           api_client.py (HTTP Client)                      ‚îÇ
‚îÇ  ‚Ä¢ Makes HTTP requests to Labellerr API                    ‚îÇ
‚îÇ  ‚Ä¢ Handles authentication                                  ‚îÇ
‚îÇ  ‚Ä¢ Polls dataset status until ready                        ‚îÇ
‚îÇ  ‚Ä¢ Manages retries & errors                                ‚îÇ
‚îÇ  ‚Ä¢ Uploads files to GCS                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ HTTPS REST API
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Labellerr API (api.labellerr.com)                 ‚îÇ
‚îÇ  ‚Ä¢ Processes requests                                      ‚îÇ
‚îÇ  ‚Ä¢ Manages your data                                       ‚îÇ
‚îÇ  ‚Ä¢ Returns responses                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Troubleshooting

### ‚ùå "AI assistant doesn't show Labellerr tools"

**Problem:** After configuration, you don't see Labellerr tools available.

**Solutions:**
1. **Completely restart** your AI assistant (Quit ‚Üí Reopen, not just refresh)
2. Check configuration file location:
   - Cursor: `~/.cursor/mcp.json` (macOS/Linux) or `%APPDATA%\Cursor\mcp.json` (Windows)
   - Claude: `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS)
3. Verify your configuration uses **absolute paths**:
   ```json
   "args": ["/full/path/to/SDKPython/labellerr/mcp_server/server.py"]
   ```
4. Test server manually:
   ```bash
   python3 /full/path/to/SDKPython/labellerr/mcp_server/server.py
   ```
   If you see errors, fix them first.

### ‚ùå "Server starts but tools fail with authentication errors"

**Problem:** Tools return 401 or 403 errors.

**Solutions:**
1. Verify credentials are correct:
   - Log into [https://pro.labellerr.com](https://pro.labellerr.com)
   - Get fresh API Key, API Secret, and Client ID
2. Check credentials in config file (not `.env`!)
3. Make sure there are no extra spaces or quotes in credentials
4. Test credentials with a simple API call:
   ```python
   from labellerr.mcp_server.api_client import LabellerrAPIClient
   client = LabellerrAPIClient(api_key="...", api_secret="...", client_id="...")
   print(client.list_projects())
   ```

### ‚ùå "File upload fails"

**Problem:** Uploading files returns errors.

**Solutions:**
1. Verify file paths exist and are readable:
   ```bash
   ls -la /path/to/your/files
   ```
2. Check file extensions match data type:
   - Image: `.jpg`, `.jpeg`, `.png`, `.tiff`
   - Video: `.mp4`
   - Audio: `.mp3`, `.wav`
   - Document: `.pdf`
3. Ensure internet connection for GCS uploads
4. Check file permissions (must be readable)

### ‚ùå "Python version or dependency errors"

**Problem:** Server won't start due to Python or package issues.

**Solutions:**
1. Check Python version (need 3.8+):
   ```bash
   python3 --version
   ```
2. Install dependencies:
   ```bash
   cd /path/to/SDKPython
   pip install -r requirements.txt
   ```
3. If using virtual environment, make sure it's activated
4. Try reinstalling packages:
   ```bash
   pip install --upgrade -r requirements.txt
   ```

### ‚ùå "Rate limit errors (429)"

**Problem:** Getting "Too Many Requests" errors.

**Solutions:**
1. Wait a few minutes before retrying
2. Reduce frequency of requests
3. The API client has automatic retry built-in
4. Contact support if limits are too restrictive

### üêõ Enable Debug Logging

If you're still having issues, enable detailed logging:

1. Add to your MCP config:
   ```json
   "env": {
     "LABELLERR_API_KEY": "...",
     "LABELLERR_API_SECRET": "...",
     "LABELLERR_CLIENT_ID": "...",
     "LOG_LEVEL": "DEBUG"
   }
   ```

2. Restart AI assistant and check logs

3. Logs go to stderr - check your AI assistant's console/logs

## Frequently Asked Questions (FAQ)

### Q: Do I need to install the full Labellerr SDK?
**A:** No! This MCP server is completely independent. It only needs `requests`, `mcp`, and standard Python libraries. Just run:
```bash
pip install -r requirements.txt
```

### Q: Can I use this with multiple AI assistants?
**A:** Yes! You can configure it in both Cursor and Claude Desktop (or any MCP-compatible client). Just add the configuration to each one.

### Q: Where do I get my API credentials?
**A:** Log into your Labellerr account at [https://pro.labellerr.com](https://pro.labellerr.com) and navigate to your account settings or API section to generate credentials.

### Q: Does this work on Windows?
**A:** Yes! Just use Windows paths in your configuration:
```json
"args": ["C:\\path\\to\\SDKPython\\labellerr\\mcp_server\\server.py"]
```
And the config file location is `%APPDATA%\Cursor\mcp.json`

### Q: Can I use this server from regular Python code (not just AI assistants)?
**A:** Yes! You can import and use `api_client.py` directly:
```python
from labellerr.mcp_server.api_client import LabellerrAPIClient
client = LabellerrAPIClient(api_key="...", api_secret="...", client_id="...")
projects = client.list_projects()
```

### Q: What happens if my API credentials change?
**A:** Update your AI assistant's MCP configuration file with new credentials and restart the assistant.

### Q: Can I limit which tools are available?
**A:** Currently, all 22 tools are exposed. If you need custom filtering, you can modify `tools.py` to remove unwanted tools from `ALL_TOOLS`.

### Q: Is my data secure?
**A:** Yes! All communication uses HTTPS. Your credentials are stored locally in your MCP config. The server only runs locally on your machine and communicates directly with Labellerr's API.

### Q: How do I update to the latest version?
**A:** Pull the latest code from the repository and reinstall dependencies:
```bash
git pull
pip install -r requirements.txt
```
Then restart your AI assistant.

### Q: Can I run this on a remote server?
**A:** The current implementation uses STDIO (standard input/output) for communication, which requires local execution. For remote deployment, you'd need to modify it to use HTTP transport instead.

### Q: What annotation types are supported?
**A:** All Labellerr annotation types:
- Bounding Box
- Polygon
- Dot/Point
- Classification (radio, checkbox, dropdown)
- Text input
- Audio annotation
- Video frame annotation

### Q: How do I report bugs or request features?
**A:** Open an issue in the repository or contact Labellerr support at support@labellerr.com

## Development

### Three-Step Architecture

The MCP server follows the SDK's three-step workflow for project creation:
1. **Dataset Creation**: Upload files, create dataset, poll status until ready
2. **Template Creation**: Define annotation questions and create template
3. **Project Creation**: Link dataset and template with rotation config

This architecture ensures datasets are fully processed before being used in projects.

### Adding New Tools

1. Define the tool schema in `tools.py`:
```python
{
    "name": "new_tool_name",
    "description": "What the tool does",
    "inputSchema": {
        "type": "object",
        "properties": {
            "param1": {
                "type": "string",
                "description": "Parameter description"
            }
        },
        "required": ["param1"]
    }
}
```

2. Add API method to `api_client.py`:
```python
def new_api_method(self, param1: str) -> Dict[str, Any]:
    """API method description"""
    url = f"{self.BASE_URL}/endpoint"
    return self._make_request("POST", url, json={"param1": param1})
```

3. Implement handler in `server.py`:
```python
async def _handle_category_tool(self, name: str, args: dict) -> dict:
    if name == "new_tool_name":
        result = await asyncio.to_thread(
            self.api_client.new_api_method,
            args["param1"]
        )
        return result
```

4. Add tests to `test_mcp_server.py`

### Running Tests During Development

```bash
# Run all tests
pytest tests/integration/test_mcp_server.py -v

# Run specific test class
pytest tests/integration/test_mcp_server.py::TestDatasetOperations -v

# Run specific test
pytest tests/integration/test_mcp_server.py::TestDatasetOperations::test_create_dataset_with_folder -v

# Run with detailed output
pytest tests/integration/test_mcp_server.py -v -s
```

## API Reference

### LabellerrAPIClient Methods

**Dataset Operations:**
- `create_dataset(dataset_name, data_type, ...)` - Create a dataset
- `get_dataset(dataset_id)` - Get dataset details
- `list_datasets(data_type, scope)` - List datasets
- `delete_dataset(dataset_id)` - Delete a dataset
- `upload_files_to_connector(file_paths)` - Upload files
- `upload_folder_to_connector(folder_path, data_type)` - Upload folder

**Template Operations:**
- `create_annotation_template(template_name, data_type, questions)` - Create template
- `get_annotation_template(template_id)` - Get template details

**Project Operations:**
- `create_project(project_name, data_type, attached_datasets, ...)` - Create project
- `get_project(project_id)` - Get project details
- `list_projects()` - List all projects
- `update_project_rotations(project_id, rotations)` - Update rotations

**Export Operations:**
- `create_export(project_id, export_name, ...)` - Create export
- `check_export_status(project_id, report_ids)` - Check export status
- `get_export_download_url(project_id, export_id)` - Get download URL

## Resources

- **Labellerr Documentation:** [docs.labellerr.com](https://docs.labellerr.com)
- **Labellerr API:** [api.labellerr.com](https://api.labellerr.com)
- **MCP Protocol:** [modelcontextprotocol.io](https://modelcontextprotocol.io)
- **Support Email:** support@labellerr.com

## License

MIT License - see LICENSE file for details.

---

**Pure API Implementation** - Independent of SDK Changes ‚Ä¢ Built with ‚ù§Ô∏è for the Labellerr community
